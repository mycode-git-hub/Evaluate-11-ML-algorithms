{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "df9c1d8d",
   "metadata": {
    "cell_number": 1
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Benchmarking 11 ML Algorithms for Anomaly Detection in Survey Research (v3)\n",
    "===========================================================================\n",
    "- AE: trained on normals only, deeper architecture, 97.5th pct threshold\n",
    "- 8 transductive algorithms: uniform 97.5th percentile threshold\n",
    "- Stray: EVT p-value < 0.05\n",
    "- OCSVM & IF: sensitivity analysis on contamination parameter\n",
    "- 5-fold stratified CV for model-based algorithms\n",
    "- Parameter tuning for all algorithms\n",
    "\"\"\"\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import gumbel_r\n",
    "from sklearn.neighbors import NearestNeighbors, LocalOutlierFactor\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import (roc_auc_score, precision_score, recall_score,\n",
    "                             f1_score, confusion_matrix, average_precision_score)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5f0969ce",
   "metadata": {
    "cell_number": 2
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "STEP 1: Data\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "\n",
    "# ============================================================\n",
    "# 1. DATA\n",
    "# ============================================================\n",
    "print(\"=\"*70); print(\"STEP 1: Data\"); print(\"=\"*70)\n",
    "df = pd.read_csv(\n",
    "    r'G:\\\\My Drive\\\\WorkingFolder\\\\AI and Machine learning\\\\'\n",
    "    r'AI in detecting aberrant response patterns\\\\2 Machine learning comparisons for anomaly\\\\'\n",
    "    r'complex_survey_sim_3000.csv'\n",
    "  # r'complex_survey_sim_1800.csv'\n",
    ")\n",
    "item_cols = [c for c in df.columns if c.startswith('Item')]\n",
    "X_raw = df[item_cols].values.astype(np.float64)\n",
    "labels = df['is_anomaly'].values\n",
    "styles = df['style'].values\n",
    "n, p = X_raw.shape\n",
    "anomaly_types = ['acquiescence','extreme','careless','random','straightline','alternating']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "f6062226",
   "metadata": {
    "cell_number": 3
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 3000 x 85, Normal=2700, Anomaly=300\n",
      "  acquiescence: 72\n",
      "  extreme: 60\n",
      "  careless: 60\n",
      "  random: 48\n",
      "  straightline: 36\n",
      "  alternating: 24\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "print(f\"Data: {n} x {p}, Normal={sum(labels==0)}, Anomaly={sum(labels==1)}\")\n",
    "for s in anomaly_types: print(f\"  {s}: {sum(styles==s)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9b920583",
   "metadata": {
    "cell_number": 4
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing: 0\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "# Impute + scale\n",
    "X_imp = X_raw.copy()\n",
    "for j in range(p):\n",
    "    m = np.isnan(X_imp[:,j]); X_imp[m,j] = np.nanmedian(X_imp[:,j])\n",
    "X_01 = MinMaxScaler().fit_transform(X_imp)\n",
    "X_std = StandardScaler().fit_transform(X_imp)\n",
    "M_raw = (~np.isnan(X_raw)).astype(float)\n",
    "print(f\"Missing: {np.isnan(X_raw).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "fe0a25b3",
   "metadata": {
    "cell_number": 5
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 2: Tune k\n",
      "======================================================================\n",
      "  k= 5: LOF AUC=0.9390\n",
      "  k=10: LOF AUC=0.9516\n",
      "  k=15: LOF AUC=0.9532\n",
      "  k=20: LOF AUC=0.9535\n",
      "Selected k=20\n"
     ]
    }
   ],
   "source": [
    "# Cell 5\n",
    "# ============================================================\n",
    "# 2. TUNE k\n",
    "# ============================================================\n",
    "print(\"\\n\"+\"=\"*70); print(\"STEP 2: Tune k\"); print(\"=\"*70)\n",
    "k_cands = [5,10,15,20]\n",
    "best_k, best_auc_k = 10, 0\n",
    "for k in k_cands:\n",
    "    lof_t = LocalOutlierFactor(n_neighbors=k, contamination='auto', novelty=False)\n",
    "    lof_t.fit_predict(X_std)\n",
    "    s = -lof_t.negative_outlier_factor_\n",
    "    a = roc_auc_score(labels, s)\n",
    "    print(f\"  k={k:2d}: LOF AUC={a:.4f}\")\n",
    "    if a > best_auc_k: best_auc_k=a; best_k=k\n",
    "K = best_k; print(f\"Selected k={K}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fd1c1174",
   "metadata": {
    "cell_number": 6
   },
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "K_C = K+5\n",
    "nn = NearestNeighbors(n_neighbors=K_C+1, metric='euclidean', n_jobs=-1)\n",
    "nn.fit(X_std)\n",
    "dist_all, idx_all = nn.kneighbors(X_std)\n",
    "dist_all = dist_all[:,1:]; idx_all = idx_all[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "66d1b724",
   "metadata": {
    "cell_number": 7
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 97.5th percentile\n"
     ]
    }
   ],
   "source": [
    "# Cell 7\n",
    "THR_PCT = 97.5\n",
    "print(f\"Threshold: {THR_PCT}th percentile\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3c4da4a0",
   "metadata": {
    "cell_number": 8,
    "lines_to_next_cell": 1
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 3: 8 Transductive algorithms\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 8\n",
    "# ============================================================\n",
    "# 3. TRANSDUCTIVE ALGORITHMS\n",
    "# ============================================================\n",
    "print(\"\\n\"+\"=\"*70); print(\"STEP 3: 8 Transductive algorithms\"); print(\"=\"*70)\n",
    "scores = {}; predictions = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "64a4ab14",
   "metadata": {
    "cell_number": 9,
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "# Cell 9\n",
    "def classify_pct(s, pct=THR_PCT):\n",
    "    t = np.percentile(s, pct); return (s>t).astype(int), t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "371a984c",
   "metadata": {
    "cell_number": 10
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [1] KNN-AGG\n",
      "      k_min=15,k_max=20, thr=56.749, flagged=75\n"
     ]
    }
   ],
   "source": [
    "# Cell 10\n",
    "# 1. KNN-AGG\n",
    "print(\"  [1] KNN-AGG\")\n",
    "K_MIN = max(1, K-5)\n",
    "knn_s = np.sum(dist_all[:, K_MIN:K], axis=1)\n",
    "scores['KNN-AGG']=knn_s; predictions['KNN-AGG'],t=classify_pct(knn_s)\n",
    "print(f\"      k_min={K_MIN},k_max={K}, thr={t:.3f}, flagged={predictions['KNN-AGG'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "9918e409",
   "metadata": {
    "cell_number": 11
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [2] LOF\n",
      "      k=20, thr=1.423, flagged=75\n"
     ]
    }
   ],
   "source": [
    "# Cell 11\n",
    "# 2. LOF\n",
    "print(\"  [2] LOF\")\n",
    "lof = LocalOutlierFactor(n_neighbors=K, contamination='auto', novelty=False, n_jobs=-1)\n",
    "lof.fit_predict(X_std)\n",
    "lof_s = -lof.negative_outlier_factor_\n",
    "scores['LOF']=lof_s; predictions['LOF'],t=classify_pct(lof_s)\n",
    "print(f\"      k={K}, thr={t:.3f}, flagged={predictions['LOF'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "7913f9e9",
   "metadata": {
    "cell_number": 12
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [3] COF\n",
      "      k=20, thr=10.542, flagged=75\n"
     ]
    }
   ],
   "source": [
    "# Cell 12\n",
    "# 3. COF\n",
    "print(\"  [3] COF\")\n",
    "cof_s = np.zeros(n)\n",
    "for i in range(n):\n",
    "    nbs = idx_all[i,:K]; cost=0.0; rem=list(nbs); vis=[i]\n",
    "    for step in range(K):\n",
    "        md=np.inf; best=-1\n",
    "        for r in rem:\n",
    "            for v in vis:\n",
    "                d=np.linalg.norm(X_std[v]-X_std[r])\n",
    "                if d<md: md=d; best=r\n",
    "        if best>=0: cost+=md*(K-step)/K; rem.remove(best); vis.append(best)\n",
    "    nc = np.mean([np.mean(dist_all[nb,:K]) for nb in nbs])\n",
    "    cof_s[i] = cost/(nc+1e-10)\n",
    "scores['COF']=cof_s; predictions['COF'],t=classify_pct(cof_s)\n",
    "print(f\"      k={K}, thr={t:.3f}, flagged={predictions['COF'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "80db093b",
   "metadata": {
    "cell_number": 13
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [4] INFLO\n",
      "      k=20, thr=1.467, flagged=75\n"
     ]
    }
   ],
   "source": [
    "# Cell 13\n",
    "# 4. INFLO\n",
    "print(\"  [4] INFLO\")\n",
    "inflo_s = np.zeros(n)\n",
    "rnn = [set() for _ in range(n)]\n",
    "for i in range(n):\n",
    "    for j in idx_all[i,:K]: rnn[j].add(i)\n",
    "for i in range(n):\n",
    "    inf_set = set(idx_all[i,:K]) | rnn[i]\n",
    "    if not inf_set: inflo_s[i]=1.0; continue\n",
    "    di = 1.0/(np.mean(dist_all[i,:K])+1e-10)\n",
    "    dn = [1.0/(np.mean(dist_all[j,:K])+1e-10) for j in inf_set]\n",
    "    inflo_s[i] = np.mean(dn)/(di+1e-10)\n",
    "scores['INFLO']=inflo_s; predictions['INFLO'],t=classify_pct(inflo_s)\n",
    "print(f\"      k={K}, thr={t:.3f}, flagged={predictions['INFLO'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a1f4833e",
   "metadata": {
    "cell_number": 14
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [5] KDEOS\n",
      "      k=20, thr=2.776, flagged=75\n"
     ]
    }
   ],
   "source": [
    "# Cell 14\n",
    "# 5. KDEOS\n",
    "print(\"  [5] KDEOS\")\n",
    "kde_r = np.zeros(n)\n",
    "for i in range(n):\n",
    "    bw=max(dist_all[i,K-1],1e-10)\n",
    "    kde_r[i] = np.mean(np.exp(-0.5*(dist_all[i,:K]/bw)**2))/(bw+1e-10)\n",
    "mu_k,std_k = np.mean(kde_r), np.std(kde_r)+1e-10\n",
    "kdeos_s = -(kde_r-mu_k)/std_k\n",
    "scores['KDEOS']=kdeos_s; predictions['KDEOS'],t=classify_pct(kdeos_s)\n",
    "print(f\"      k={K}, thr={t:.3f}, flagged={predictions['KDEOS'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "67daa75e",
   "metadata": {
    "cell_number": 15
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [6] LDF\n",
      "      k=20, thr=1.473, flagged=75\n"
     ]
    }
   ],
   "source": [
    "# Cell 15\n",
    "# 6. LDF\n",
    "print(\"  [6] LDF\")\n",
    "lde = np.zeros(n)\n",
    "for i in range(n):\n",
    "    bw=dist_all[i,K-1]+1e-10\n",
    "    lde[i] = np.mean(np.exp(-0.5*(dist_all[i,:K]/bw)**2))/bw\n",
    "ldf_s = np.zeros(n)\n",
    "for i in range(n):\n",
    "    ldf_s[i] = np.mean(lde[idx_all[i,:K]])/(lde[i]+1e-10)\n",
    "scores['LDF']=ldf_s; predictions['LDF'],t=classify_pct(ldf_s)\n",
    "print(f\"      k={K}, thr={t:.3f}, flagged={predictions['LDF'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "542e1fed",
   "metadata": {
    "cell_number": 16
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [7] LDOF\n",
      "      k=20, thr=1.237, flagged=75\n"
     ]
    }
   ],
   "source": [
    "# Cell 16\n",
    "# 7. LDOF\n",
    "print(\"  [7] LDOF\")\n",
    "ldof_s = np.zeros(n)\n",
    "for i in range(n):\n",
    "    nbs=idx_all[i,:K]; di=np.mean(dist_all[i,:K])\n",
    "    pts=X_std[nbs]\n",
    "    if len(nbs)>1:\n",
    "        pw=cdist(pts,pts,'euclidean'); tri=np.triu_indices(len(nbs),k=1)\n",
    "        Dn=np.mean(pw[tri]) if len(tri[0])>0 else 1.0\n",
    "    else: Dn=1.0\n",
    "    ldof_s[i]=di/(Dn+1e-10)\n",
    "scores['LDOF']=ldof_s; predictions['LDOF'],t=classify_pct(ldof_s)\n",
    "print(f\"      k={K}, thr={t:.3f}, flagged={predictions['LDOF'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "70b4b3d7",
   "metadata": {
    "cell_number": 17
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  [8] Stray (EVT)\n",
      "      k=20, alpha=0.05, flagged=158\n"
     ]
    }
   ],
   "source": [
    "# Cell 17\n",
    "# 8. Stray\n",
    "print(\"  [8] Stray (EVT)\")\n",
    "mg = np.array([np.max(np.diff(dist_all[i,:K])) if K>1 else 0 for i in range(n)])\n",
    "mu_g=np.mean(mg); sig_g=np.std(mg)+1e-10\n",
    "beta_g=sig_g*np.sqrt(6)/np.pi; mu_gum=mu_g-0.5772*beta_g\n",
    "stray_pv = 1.0-gumbel_r.cdf(mg, loc=mu_gum, scale=beta_g)\n",
    "stray_s = -np.log(stray_pv+1e-15)\n",
    "scores['Stray']=stray_s\n",
    "stray_alpha=0.05\n",
    "predictions['Stray']=(stray_pv<stray_alpha).astype(int)\n",
    "print(f\"      k={K}, alpha={stray_alpha}, flagged={predictions['Stray'].sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3707df8a",
   "metadata": {
    "cell_number": 18
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 4: Autoencoder (normals only, 5-fold CV)\n",
      "======================================================================\n",
      "  NOTE: sklearn approximation. Replace with PyTorch for final paper.\n"
     ]
    }
   ],
   "source": [
    "# Cell 18\n",
    "# ============================================================\n",
    "# 4. AUTOENCODER (normals only, CV)\n",
    "# ============================================================\n",
    "print(\"\\n\"+\"=\"*70); print(\"STEP 4: Autoencoder (normals only, 5-fold CV)\"); print(\"=\"*70)\n",
    "print(\"  NOTE: sklearn approximation. Replace with PyTorch for final paper.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10160fc",
   "metadata": {
    "cell_number": 19
   },
   "source": [
    "# Cell 19\n",
    "## PYTORCH SWAP POINT ###\n",
    "Your PyTorch implementation key features to preserve:\n",
    "  - Architecture: D->64->32->16->8->16->32->64->D, Sigmoid output\n",
    "  - Train on normals ONLY\n",
    "  - Denoising: 15% dropout of observed values  \n",
    "  - Masked MSE (only score observed entries)\n",
    "  - Early stopping patience=12\n",
    "  - Threshold: 97.5th pct of TRAINING reconstruction errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "b4b8915b",
   "metadata": {
    "cell_number": 20
   },
   "outputs": [],
   "source": [
    "# Cell 20\n",
    "ae_scores = np.full(n, np.nan)\n",
    "ae_preds = np.zeros(n, dtype=int)\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d2916012",
   "metadata": {
    "cell_number": 21
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Tuning architecture...\n",
      "    deep-8          (64, 32, 16, 8, 16, 32, 64)         AUC=0.9385\n",
      "    deep-8-skip     (64, 32, 8, 32, 64)                 AUC=0.9366\n",
      "    moderate-16     (64, 16, 64)                        AUC=0.9385\n",
      "    wide-8          (128, 32, 8, 32, 128)               AUC=0.9406\n"
     ]
    }
   ],
   "source": [
    "# Cell 21\n",
    "# Architecture tuning\n",
    "print(\"  Tuning architecture...\")\n",
    "arch_cands = [\n",
    "    ((64,32,16,8,16,32,64), 'deep-8'),\n",
    "    ((64,32,8,32,64), 'deep-8-skip'),\n",
    "    ((64,16,64), 'moderate-16'),\n",
    "    ((128,32,8,32,128), 'wide-8'),\n",
    "]\n",
    "best_arch, best_arch_name, best_arch_auc = arch_cands[0][0], arch_cands[0][1], 0\n",
    "for arch, name in arch_cands:\n",
    "    fold_aucs = []\n",
    "    for tr_i, te_i in skf.split(X_01, labels):\n",
    "        tr_norm = tr_i[labels[tr_i]==0]\n",
    "        ae_t = MLPRegressor(hidden_layer_sizes=arch, activation='relu', solver='adam',\n",
    "                            max_iter=300, random_state=42, early_stopping=True,\n",
    "                            validation_fraction=0.15, n_iter_no_change=12,\n",
    "                            learning_rate_init=0.001, batch_size=128, tol=1e-5)\n",
    "        ae_t.fit(X_01[tr_norm], X_01[tr_norm])\n",
    "        recon = ae_t.predict(X_01[te_i])\n",
    "        err = np.mean((X_01[te_i]-recon)**2, axis=1)\n",
    "        if len(np.unique(labels[te_i]))>1:\n",
    "            fold_aucs.append(roc_auc_score(labels[te_i], err))\n",
    "    avg = np.mean(fold_aucs) if fold_aucs else 0\n",
    "    print(f\"    {name:15s} {str(arch):35s} AUC={avg:.4f}\")\n",
    "    if avg > best_arch_auc:\n",
    "        best_arch_auc=avg; best_arch=arch; best_arch_name=name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "2275dd98",
   "metadata": {
    "cell_number": 22
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Selected: wide-8 (128, 32, 8, 32, 128) (AUC=0.9406)\n"
     ]
    }
   ],
   "source": [
    "# Cell 22\n",
    "print(f\"  Selected: {best_arch_name} {best_arch} (AUC={best_arch_auc:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "ab7fd9ae",
   "metadata": {
    "cell_number": 23
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running final CV...\n",
      "    Fold 1: train_n=2160, thr=0.0476, flagged=61/600\n",
      "    Fold 2: train_n=2160, thr=0.0469, flagged=77/600\n",
      "    Fold 3: train_n=2160, thr=0.0492, flagged=63/600\n",
      "    Fold 4: train_n=2160, thr=0.0498, flagged=58/600\n",
      "    Fold 5: train_n=2160, thr=0.0494, flagged=70/600\n"
     ]
    }
   ],
   "source": [
    "# Cell 23\n",
    "# Final CV run\n",
    "print(\"  Running final CV...\")\n",
    "for fold, (tr_i, te_i) in enumerate(skf.split(X_01, labels)):\n",
    "    tr_norm = tr_i[labels[tr_i]==0]\n",
    "    ae = MLPRegressor(hidden_layer_sizes=best_arch, activation='relu', solver='adam',\n",
    "                      max_iter=500, random_state=42, early_stopping=True,\n",
    "                      validation_fraction=0.15, n_iter_no_change=12,\n",
    "                      learning_rate_init=0.001, batch_size=128, tol=1e-5)\n",
    "    ae.fit(X_01[tr_norm], X_01[tr_norm])\n",
    "    \n",
    "    recon_test = ae.predict(X_01[te_i])\n",
    "    err_test = np.mean((X_01[te_i]-recon_test)**2, axis=1)\n",
    "    ae_scores[te_i] = err_test\n",
    "    \n",
    "    recon_train = ae.predict(X_01[tr_norm])\n",
    "    err_train = np.mean((X_01[tr_norm]-recon_train)**2, axis=1)\n",
    "    thr_ae = np.percentile(err_train, THR_PCT)\n",
    "    ae_preds[te_i] = (err_test > thr_ae).astype(int)\n",
    "    print(f\"    Fold {fold+1}: train_n={len(tr_norm)}, thr={thr_ae:.4f}, \"\n",
    "          f\"flagged={ae_preds[te_i].sum()}/{len(te_i)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "722c3302",
   "metadata": {
    "cell_number": 24
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total flagged: 329\n"
     ]
    }
   ],
   "source": [
    "# Cell 24\n",
    "scores['Autoencoder']=ae_scores; predictions['Autoencoder']=ae_preds\n",
    "print(f\"  Total flagged: {ae_preds.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "8d293ee6",
   "metadata": {
    "cell_number": 25
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 5: OCSVM & Isolation Forest\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 25\n",
    "# ============================================================\n",
    "# 5. OCSVM & ISOLATION FOREST\n",
    "# ============================================================\n",
    "print(\"\\n\"+\"=\"*70); print(\"STEP 5: OCSVM & Isolation Forest\"); print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "773e04ae",
   "metadata": {
    "cell_number": 26
   },
   "outputs": [],
   "source": [
    "# Cell 26\n",
    "nu_values = [0.05, 0.10, 0.15, 0.20, 0.25]\n",
    "contam_values = [0.05, 0.10, 0.15, 0.20, 0.25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "22d7cb8b",
   "metadata": {
    "cell_number": 27
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  OCSVM...\n",
      "  gamma='auto'\n"
     ]
    }
   ],
   "source": [
    "# Cell 27\n",
    "# OCSVM\n",
    "print(\"\\n  OCSVM...\")\n",
    "best_gamma='scale'; best_ga=0\n",
    "for g in ['scale','auto']:\n",
    "    fa=[]\n",
    "    for tr_i,te_i in skf.split(X_std,labels):\n",
    "        try:\n",
    "            m=OneClassSVM(kernel='rbf',gamma=g,nu=0.15); m.fit(X_std[tr_i])\n",
    "            fa.append(roc_auc_score(labels[te_i], -m.decision_function(X_std[te_i])))\n",
    "        except: pass\n",
    "    avg=np.mean(fa) if fa else 0\n",
    "    if avg>best_ga: best_ga=avg; best_gamma=g\n",
    "print(f\"  gamma='{best_gamma}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "bea1fee2",
   "metadata": {
    "cell_number": 28
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    nu=0.05: flagged= 182, AUC=0.8918\n",
      "    nu=0.10: flagged= 339, AUC=0.8950\n",
      "    nu=0.15: flagged= 483, AUC=0.8998\n",
      "    nu=0.20: flagged= 631, AUC=0.9037\n",
      "    nu=0.25: flagged= 771, AUC=0.9064\n",
      "  Best nu=0.25\n"
     ]
    }
   ],
   "source": [
    "# Cell 28\n",
    "ocsvm_sens = {}\n",
    "for nu in nu_values:\n",
    "    ns=np.zeros(n); np_=np.zeros(n,dtype=int)\n",
    "    for tr_i,te_i in skf.split(X_std,labels):\n",
    "        m=OneClassSVM(kernel='rbf',gamma=best_gamma,nu=nu); m.fit(X_std[tr_i])\n",
    "        d=m.decision_function(X_std[te_i]); ns[te_i]=-d; np_[te_i]=(d<0).astype(int)\n",
    "    a=roc_auc_score(labels,ns)\n",
    "    ocsvm_sens[nu]={'scores':ns,'preds':np_,'n_flagged':np_.sum(),'auc':a}\n",
    "    print(f\"    nu={nu:.2f}: flagged={np_.sum():4d}, AUC={a:.4f}\")\n",
    "best_nu = max(nu_values, key=lambda v: ocsvm_sens[v]['auc'])\n",
    "scores['OCSVM']=ocsvm_sens[best_nu]['scores']\n",
    "predictions['OCSVM']=ocsvm_sens[best_nu]['preds']\n",
    "print(f\"  Best nu={best_nu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "bc60ef18",
   "metadata": {
    "cell_number": 29
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Isolation Forest...\n",
      "    n_est=100: AUC=0.9002\n",
      "    n_est=200: AUC=0.9140\n",
      "    n_est=300: AUC=0.9131\n",
      "  n_estimators=200\n"
     ]
    }
   ],
   "source": [
    "# Cell 29\n",
    "# Isolation Forest\n",
    "print(\"\\n  Isolation Forest...\")\n",
    "best_ne,best_ia=200,0\n",
    "for ne in [100,200,300]:\n",
    "    fa=[]\n",
    "    for tr_i,te_i in skf.split(X_std,labels):\n",
    "        m=IsolationForest(n_estimators=ne,contamination=0.15,random_state=42,n_jobs=-1)\n",
    "        m.fit(X_std[tr_i])\n",
    "        fa.append(roc_auc_score(labels[te_i],-m.decision_function(X_std[te_i])))\n",
    "    avg=np.mean(fa); print(f\"    n_est={ne}: AUC={avg:.4f}\")\n",
    "    if avg>best_ia: best_ia=avg; best_ne=ne\n",
    "print(f\"  n_estimators={best_ne}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "b72cd1ec",
   "metadata": {
    "cell_number": 30
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    contam=0.05: flagged= 155, AUC=0.9132\n",
      "    contam=0.10: flagged= 323, AUC=0.9137\n",
      "    contam=0.15: flagged= 489, AUC=0.9135\n",
      "    contam=0.20: flagged= 629, AUC=0.9138\n",
      "    contam=0.25: flagged= 784, AUC=0.9137\n",
      "  Best contam=0.2\n"
     ]
    }
   ],
   "source": [
    "# Cell 30\n",
    "if_sens = {}\n",
    "for c in contam_values:\n",
    "    cs=np.zeros(n); cp=np.zeros(n,dtype=int)\n",
    "    for tr_i,te_i in skf.split(X_std,labels):\n",
    "        m=IsolationForest(n_estimators=best_ne,contamination=c,random_state=42,n_jobs=-1)\n",
    "        m.fit(X_std[tr_i])\n",
    "        d=m.decision_function(X_std[te_i]); cs[te_i]=-d; cp[te_i]=(d<0).astype(int)\n",
    "    a=roc_auc_score(labels,cs)\n",
    "    if_sens[c]={'scores':cs,'preds':cp,'n_flagged':cp.sum(),'auc':a}\n",
    "    print(f\"    contam={c:.2f}: flagged={cp.sum():4d}, AUC={a:.4f}\")\n",
    "best_contam = max(contam_values, key=lambda v: if_sens[v]['auc'])\n",
    "scores['IsolationForest']=if_sens[best_contam]['scores']\n",
    "predictions['IsolationForest']=if_sens[best_contam]['preds']\n",
    "print(f\"  Best contam={best_contam}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "bbf9cc70",
   "metadata": {
    "cell_number": 31
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 6: Evaluation\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 31\n",
    "# ============================================================\n",
    "# 6. EVALUATION\n",
    "# ============================================================\n",
    "print(\"\\n\"+\"=\"*70); print(\"STEP 6: Evaluation\"); print(\"=\"*70)\n",
    "alg_names = ['KNN-AGG','LOF','COF','INFLO','KDEOS','LDF','LDOF',\n",
    "             'Autoencoder','OCSVM','IsolationForest','Stray']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "0ae47d53",
   "metadata": {
    "cell_number": 32
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Threshold Summary ---\n",
      "  KNN-AGG             : flagged=  75\n",
      "  LOF                 : flagged=  75\n",
      "  COF                 : flagged=  75\n",
      "  INFLO               : flagged=  75\n",
      "  KDEOS               : flagged=  75\n",
      "  LDF                 : flagged=  75\n",
      "  LDOF                : flagged=  75\n",
      "  Autoencoder         : flagged= 329\n",
      "  OCSVM               : flagged= 771\n",
      "  IsolationForest     : flagged= 629\n",
      "  Stray               : flagged= 158\n"
     ]
    }
   ],
   "source": [
    "# Cell 32\n",
    "# Threshold summary\n",
    "print(\"\\n--- Threshold Summary ---\")\n",
    "for a in alg_names:\n",
    "    print(f\"  {a:20s}: flagged={predictions[a].sum():4d}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "6108769f",
   "metadata": {
    "cell_number": 33
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Overall Performance ---\n",
      "  KNN-AGG              AUC=0.927 AP=0.842 P=1.000 R=0.250 F1=0.400 Sp=1.000 (TP=75 FP=0 FN=225)\n",
      "  LOF                  AUC=0.954 AP=0.902 P=1.000 R=0.250 F1=0.400 Sp=1.000 (TP=75 FP=0 FN=225)\n",
      "  COF                  AUC=0.833 AP=0.623 P=0.987 R=0.247 F1=0.395 Sp=1.000 (TP=74 FP=1 FN=226)\n",
      "  INFLO                AUC=0.941 AP=0.894 P=1.000 R=0.250 F1=0.400 Sp=1.000 (TP=75 FP=0 FN=225)\n",
      "  KDEOS                AUC=0.929 AP=0.847 P=1.000 R=0.250 F1=0.400 Sp=1.000 (TP=75 FP=0 FN=225)\n",
      "  LDF                  AUC=0.954 AP=0.906 P=1.000 R=0.250 F1=0.400 Sp=1.000 (TP=75 FP=0 FN=225)\n",
      "  LDOF                 AUC=0.951 AP=0.894 P=1.000 R=0.250 F1=0.400 Sp=1.000 (TP=75 FP=0 FN=225)\n",
      "  Autoencoder          AUC=0.940 AP=0.867 P=0.748 R=0.820 F1=0.782 Sp=0.969 (TP=246 FP=83 FN=54)\n",
      "  OCSVM                AUC=0.906 AP=0.785 P=0.331 R=0.850 F1=0.476 Sp=0.809 (TP=255 FP=516 FN=45)\n",
      "  IsolationForest      AUC=0.914 AP=0.763 P=0.397 R=0.833 F1=0.538 Sp=0.860 (TP=250 FP=379 FN=50)\n",
      "  Stray                AUC=0.468 AP=0.101 P=0.095 R=0.050 F1=0.066 Sp=0.947 (TP=15 FP=143 FN=285)\n"
     ]
    }
   ],
   "source": [
    "# Cell 33\n",
    "# Overall\n",
    "print(\"\\n--- Overall Performance ---\")\n",
    "overall = {}\n",
    "for a in alg_names:\n",
    "    s=scores[a]; pr=predictions[a]\n",
    "    v=~np.isnan(s); se=s[v]; le=labels[v]\n",
    "    auc_r=roc_auc_score(le,se); ap=average_precision_score(le,se)\n",
    "    prec=precision_score(labels,pr,zero_division=0)\n",
    "    rec=recall_score(labels,pr,zero_division=0)\n",
    "    f1=f1_score(labels,pr,zero_division=0)\n",
    "    tn,fp,fn,tp=confusion_matrix(labels,pr).ravel()\n",
    "    sp=tn/(tn+fp) if (tn+fp)>0 else 0\n",
    "    overall[a]={'AUC-ROC':auc_r,'AP':ap,'Precision':prec,'Recall':rec,\n",
    "                'F1':f1,'Specificity':sp,'TP':tp,'FP':fp,'FN':fn,'TN':tn}\n",
    "    print(f\"  {a:20s} AUC={auc_r:.3f} AP={ap:.3f} P={prec:.3f} R={rec:.3f} \"\n",
    "          f\"F1={f1:.3f} Sp={sp:.3f} (TP={tp} FP={fp} FN={fn})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ddb9d88a",
   "metadata": {
    "cell_number": 34
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Detection Rate by Type ---\n",
      "                 acquiescence  extreme  careless  random  straightline  alternating\n",
      "KNN-AGG                 0.000    0.367     0.067   0.479         0.139        0.875\n",
      "LOF                     0.000    0.450     0.100   0.417         0.139        0.708\n",
      "COF                     0.056    0.300     0.200   0.521         0.056        0.542\n",
      "INFLO                   0.000    0.450     0.117   0.500         0.139        0.500\n",
      "KDEOS                   0.000    0.350     0.083   0.500         0.111        0.875\n",
      "LDF                     0.000    0.450     0.100   0.438         0.139        0.667\n",
      "LDOF                    0.000    0.550     0.117   0.417         0.083        0.500\n",
      "Autoencoder             0.764    0.950     0.900   1.000         0.222        1.000\n",
      "OCSVM                   0.764    1.000     0.867   1.000         0.444        1.000\n",
      "IsolationForest         0.736    0.967     0.867   1.000         0.417        1.000\n",
      "Stray                   0.014    0.033     0.067   0.042         0.111        0.083\n"
     ]
    }
   ],
   "source": [
    "# Cell 34\n",
    "# Per-type detection rate\n",
    "print(\"\\n--- Detection Rate by Type ---\")\n",
    "det_m = pd.DataFrame(index=alg_names, columns=anomaly_types, dtype=float)\n",
    "for a in alg_names:\n",
    "    for at in anomaly_types:\n",
    "        idx=np.where(styles==at)[0]\n",
    "        det_m.loc[a,at]=predictions[a][idx].mean() if len(idx)>0 else 0\n",
    "print(det_m.round(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "0c48e629",
   "metadata": {
    "cell_number": 35
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- AUC by Type ---\n",
      "                 acquiescence  extreme  careless  random  straightline  alternating\n",
      "KNN-AGG                 0.888    0.985     0.976   1.000         0.683        1.000\n",
      "LOF                     0.983    1.000     0.978   1.000         0.684        1.000\n",
      "COF                     0.756    0.849     0.885   0.989         0.626        0.898\n",
      "INFLO                   0.980    1.000     0.983   1.000         0.575        1.000\n",
      "KDEOS                   0.896    0.985     0.980   1.000         0.674        1.000\n",
      "LDF                     0.987    1.000     0.984   1.000         0.666        1.000\n",
      "LDOF                    0.980    1.000     0.983   1.000         0.663        0.990\n",
      "Autoencoder             0.960    0.994     0.987   1.000         0.613        1.000\n",
      "OCSVM                   0.878    1.000     0.922   0.997         0.598        1.000\n",
      "IsolationForest         0.874    0.984     0.936   0.995         0.674        1.000\n",
      "Stray                   0.394    0.534     0.404   0.452         0.580        0.555\n"
     ]
    }
   ],
   "source": [
    "# Cell 35\n",
    "# Per-type AUC\n",
    "print(\"\\n--- AUC by Type ---\")\n",
    "auc_m = pd.DataFrame(index=alg_names, columns=anomaly_types, dtype=float)\n",
    "for a in alg_names:\n",
    "    s=scores[a]\n",
    "    for at in anomaly_types:\n",
    "        mask=(styles==at)|(labels==0); v=mask&~np.isnan(s)\n",
    "        y_s=labels[v]; s_s=s[v]\n",
    "        auc_m.loc[a,at]=roc_auc_score(y_s,s_s) if len(np.unique(y_s))>1 else np.nan\n",
    "print(auc_m.round(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "bcd728e7",
   "metadata": {
    "cell_number": 36
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- F1 by Type ---\n",
      "                 acquiescence  extreme  careless  random  straightline  alternating\n",
      "KNN-AGG                 0.000    0.537     0.125   0.648         0.244        0.933\n",
      "LOF                     0.000    0.621     0.182   0.588         0.244        0.829\n",
      "COF                     0.104    0.456     0.329   0.676         0.103        0.684\n",
      "INFLO                   0.000    0.621     0.209   0.667         0.244        0.667\n",
      "KDEOS                   0.000    0.519     0.154   0.667         0.200        0.933\n",
      "LDF                     0.000    0.621     0.182   0.609         0.244        0.800\n",
      "LDOF                    0.000    0.710     0.209   0.588         0.154        0.667\n",
      "Autoencoder             0.524    0.570     0.548   0.536         0.126        0.366\n",
      "OCSVM                   0.171    0.189     0.166   0.157         0.056        0.085\n",
      "IsolationForest         0.210    0.233     0.212   0.202         0.070        0.112\n",
      "Stray                   0.009    0.020     0.039   0.021         0.044        0.024\n"
     ]
    }
   ],
   "source": [
    "# Cell 36\n",
    "# Per-type F1\n",
    "print(\"\\n--- F1 by Type ---\")\n",
    "f1_m = pd.DataFrame(index=alg_names, columns=anomaly_types, dtype=float)\n",
    "for a in alg_names:\n",
    "    for at in anomaly_types:\n",
    "        mask=(styles==at)|(labels==0)\n",
    "        f1_m.loc[a,at]=f1_score(labels[mask],predictions[a][mask],zero_division=0)\n",
    "print(f1_m.round(3).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "535ecf5f",
   "metadata": {
    "cell_number": 37
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "STEP 7: Save\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 37\n",
    "# ============================================================\n",
    "# 7. SAVE\n",
    "# ============================================================\n",
    "import os\n",
    "print(\"\\n\" + \"=\"*70); print(\"STEP 7: Save\"); print(\"=\"*70)\n",
    "\n",
    "output_dir = os.path.join(\n",
    "    r\"G:\\My Drive\\WorkingFolder\",\n",
    "    \"AI and Machine learning\",\n",
    "    \"AI in detecting aberrant response patterns\",\n",
    "    \"2 Machine learning comparisons for anomaly\"\n",
    ")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "det_m.to_csv(os.path.join(output_dir, 'v3_detection_rates.csv'))\n",
    "auc_m.to_csv(os.path.join(output_dir, 'v3_auc_by_type.csv'))\n",
    "f1_m.to_csv(os.path.join(output_dir, 'v3_f1_by_type.csv'))\n",
    "pd.DataFrame(overall).T.to_csv(os.path.join(output_dir, 'v3_overall.csv'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "fcb74082",
   "metadata": {
    "cell_number": 38
   },
   "outputs": [],
   "source": [
    "# Cell 38\n",
    "sdf = pd.DataFrame(scores)\n",
    "sdf['is_anomaly']=labels; sdf['style']=styles; sdf['respondent_id']=df['respondent_id'].values\n",
    "for a in alg_names: sdf[f'{a}_pred']=predictions[a]\n",
    "sdf.to_csv(os.path.join(output_dir, 'v3_raw_scores.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f0369762",
   "metadata": {
    "cell_number": 39
   },
   "outputs": [],
   "source": [
    "# Cell 39\n",
    "# Sensitivity\n",
    "sr=[]\n",
    "for nu in nu_values:\n",
    "    r={'alg':'OCSVM','param':'nu','val':nu,'flagged':ocsvm_sens[nu]['n_flagged'],'AUC':ocsvm_sens[nu]['auc']}\n",
    "    for at in anomaly_types: r[f'det_{at}']=ocsvm_sens[nu]['preds'][styles==at].mean()\n",
    "    sr.append(r)\n",
    "for c in contam_values:\n",
    "    r={'alg':'IF','param':'contam','val':c,'flagged':if_sens[c]['n_flagged'],'AUC':if_sens[c]['auc']}\n",
    "    for at in anomaly_types: r[f'det_{at}']=if_sens[c]['preds'][styles==at].mean()\n",
    "    sr.append(r)\n",
    "pd.DataFrame(sr).to_csv(os.path.join(output_dir,'v3_sensitivity.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "073dfc8b",
   "metadata": {
    "cell_number": 40
   },
   "outputs": [],
   "source": [
    "# Cell 40\n",
    "# Parameters\n",
    "pd.DataFrame({\n",
    "    'Algorithm':alg_names,\n",
    "    'Params':[f'k_min={K-5},k_max={K}',f'k={K}',f'k={K}',f'k={K}',f'k={K}',f'k={K}',f'k={K}',\n",
    "              f'arch={best_arch}',f'nu={best_nu},g={best_gamma}',\n",
    "              f'c={best_contam},ne={best_ne}',f'k={K},a={stray_alpha}'],\n",
    "    'Threshold':[f'{THR_PCT}pct']*7+[f'{THR_PCT}pct(train-normals)','Dec.bndry','Dec.bndry',f'EVT p<{stray_alpha}'],\n",
    "    'TrainOn':['All']*7+['Normals','All(CV)','All(CV)','All'],\n",
    "    'CV':['No']*7+['5-fold']*3+['No'],\n",
    "    'Flagged':[predictions[a].sum() for a in alg_names]\n",
    "}).to_csv(os.path.join(output_dir, 'v3_params.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "8045ac66",
   "metadata": {
    "cell_number": 41
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved pickle: G:\\My Drive\\WorkingFolder\\AI and Machine learning\\AI in detecting aberrant response patterns\\2 Machine learning comparisons for anomaly\\v3_data.pkl\n"
     ]
    }
   ],
   "source": [
    "# Cell 41\n",
    "# Save objects for plotting script\n",
    "import pickle\n",
    "pkl_path = os.path.join(output_dir, 'v3_data.pkl')\n",
    "\n",
    "with open(pkl_path, 'wb') as f:\n",
    "    pickle.dump({\n",
    "        'scores':scores,'predictions':predictions,'overall':overall,\n",
    "        'det_m':det_m,'auc_m':auc_m,'f1_m':f1_m,\n",
    "        'alg_names':alg_names,'anomaly_types':anomaly_types,\n",
    "        'ocsvm_sens':ocsvm_sens,'if_sens':if_sens,\n",
    "        'nu_values':nu_values,'contam_values':contam_values,\n",
    "        'styles':styles,'labels':labels,\n",
    "        'K':K,'THR_PCT':THR_PCT,'best_nu':best_nu,'best_contam':best_contam,\n",
    "        'stray_alpha':stray_alpha,'best_arch':best_arch,'best_gamma':best_gamma,'best_ne':best_ne\n",
    "    }, f)\n",
    "\n",
    "print(f\"Saved pickle: {pkl_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "133d20d8",
   "metadata": {
    "cell_number": 42
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All CSVs and data saved. Run v3_plots.py for figures.\n",
      "======================================================================\n",
      "DONE\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Cell 42\n",
    "print(\"\\nAll CSVs and data saved. Run v3_plots.py for figures.\")\n",
    "print(\"=\"*70); print(\"DONE\"); print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
